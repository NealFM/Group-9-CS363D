{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributors: \n",
    "Kyle McCarver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "from time import sleep\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from amb_sdk.sdk import DarwinSdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Darwin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login\n",
    "ds = DarwinSdk()\n",
    "file = open(\"login.txt\", \"r\")\n",
    "username = file.readline(0)\n",
    "password = file.readline(1)\n",
    "ds.set_url('https://amb-demo-api.sparkcognition.com/v1/')\n",
    "status, msg = ds.auth_login_user('username', 'password')\n",
    "if not status:\n",
    "    print(msg)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Path\n",
    "Make sure to set this to your local machine's path to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data:\n",
    "Data used in this project:\n",
    "https://data.austintexas.gov/Building-and-Development/Issued-Construction-Permits/3syk-w9eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (53,54,56,58,59,60,61,62,63,64,65,66) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Permit Type Desc', 'Permit Num', 'Permit Class Mapped', 'Permit Class', 'Condominium', 'Project Name', 'Description', 'TCAD ID', 'Property Legal Description', 'Issued Date', 'Day Issued', 'Issued In Last 30 Days', 'Issuance Method', 'Status Current', 'Status Date', 'Expires Date', 'Completed Date', 'Total Existing Bldg SQFT', 'Remodel Repair SQFT', 'Total New Add SQFT', 'Total Valuation Remodel', 'Building Valuation', 'Building Valuation Remodel', 'Electrical Valuation', 'Electrical Valuation Remodel', 'Mechanical Valuation', 'Mechanical Valuation Remodel', 'Plumbing Valuation', 'Plumbing Valuation Remodel', 'MedGas Valuation', 'MedGas Valuation Remodel', 'Original Address 1', 'Original City', 'Original State', 'Original Zip', 'Council District', 'Jurisdiction', 'Link', 'Project ID', 'Location', 'Contractor Trade', 'Contractor Company Name', 'Contractor Full Name', 'Contractor Phone', 'Contractor Address 1', 'Contractor Address 2', 'Contractor City', 'Contractor Zip', 'Applicant Full Name', 'Applicant Organization', 'Applicant Phone', 'Applicant Address 1', 'Applicant Address 2', 'Applicant City', 'Applicant Zip', 'Certificate Of Occupancy', 'Total Lot SQFT']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Permit Type</th>\n",
       "      <th>Work Class</th>\n",
       "      <th>Applied Date</th>\n",
       "      <th>Calendar Year Issued</th>\n",
       "      <th>Fiscal Year Issued</th>\n",
       "      <th>Total Job Valuation</th>\n",
       "      <th>Number Of Floors</th>\n",
       "      <th>Housing Units</th>\n",
       "      <th>Master Permit Num</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1557453</th>\n",
       "      <td>EP</td>\n",
       "      <td>New</td>\n",
       "      <td>2002/04/30</td>\n",
       "      <td>2002</td>\n",
       "      <td>2002</td>\n",
       "      <td>470247.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>690668.0</td>\n",
       "      <td>30.364092</td>\n",
       "      <td>-97.780764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431488</th>\n",
       "      <td>EP</td>\n",
       "      <td>Wall</td>\n",
       "      <td>2016/04/18</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11515070.0</td>\n",
       "      <td>30.357097</td>\n",
       "      <td>-97.731317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221236</th>\n",
       "      <td>PP</td>\n",
       "      <td>Remodel</td>\n",
       "      <td>1987/09/09</td>\n",
       "      <td>1987</td>\n",
       "      <td>1987</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>752648.0</td>\n",
       "      <td>30.365089</td>\n",
       "      <td>-97.705924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257171</th>\n",
       "      <td>DS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990/11/28</td>\n",
       "      <td>1990</td>\n",
       "      <td>1991</td>\n",
       "      <td>108150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>597288.0</td>\n",
       "      <td>30.350383</td>\n",
       "      <td>-97.612943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143311</th>\n",
       "      <td>PP</td>\n",
       "      <td>New</td>\n",
       "      <td>1998/09/04</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998</td>\n",
       "      <td>890000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>657332.0</td>\n",
       "      <td>30.231502</td>\n",
       "      <td>-97.837432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Permit Type Work Class Applied Date  Calendar Year Issued  \\\n",
       "1557453          EP        New   2002/04/30                  2002   \n",
       "431488           EP       Wall   2016/04/18                  2016   \n",
       "1221236          PP    Remodel   1987/09/09                  1987   \n",
       "1257171          DS        NaN   1990/11/28                  1990   \n",
       "1143311          PP        New   1998/09/04                  1998   \n",
       "\n",
       "         Fiscal Year Issued  Total Job Valuation  Number Of Floors  \\\n",
       "1557453                2002             470247.0               2.0   \n",
       "431488                 2016                  NaN               NaN   \n",
       "1221236                1987              10000.0               NaN   \n",
       "1257171                1991             108150.0               NaN   \n",
       "1143311                1998             890000.0               3.0   \n",
       "\n",
       "         Housing Units  Master Permit Num   Latitude  Longitude  \n",
       "1557453            2.0           690668.0  30.364092 -97.780764  \n",
       "431488             NaN         11515070.0  30.357097 -97.731317  \n",
       "1221236            1.0           752648.0  30.365089 -97.705924  \n",
       "1257171            NaN           597288.0  30.350383 -97.612943  \n",
       "1143311           24.0           657332.0  30.231502 -97.837432  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFile = \"./Issued_Construction_Permits.csv\"\n",
    "filename= \"train.csv\"\n",
    "test = 'test.csv'\n",
    "data = pd.read_csv(dataFile, skipinitialspace=True)\n",
    "\n",
    "#Columns with detected mixed types\n",
    "mixedData_col = [52,54,56,58,59,60,61,62,63,64,65,66]\n",
    "\n",
    "columnsNames = data.columns.values\n",
    "# Important features calculated from the model in the master notebook\n",
    "\n",
    "'''\n",
    "Master Permit Num       0.116584\n",
    "Housing Units           0.039151\n",
    "Total Job Valuation     0.027820\n",
    "Number Of Floors        0.025094\n",
    "Fiscal Year Issued      0.016996\n",
    "Calendar Year Issued    0.016561\n",
    "Longitude               0.014342\n",
    "Latitude                0.013554\n",
    "Work Class = New        0.012211'''\n",
    "important_features = [\"Permit Type\", \"Master Permit Num\", \"Housing Units\", \"Total Job Valuation\", \"Number Of Floors\", \n",
    "                      \"Fiscal Year Issued\", \"Calendar Year Issued\", \"Longitude\", \"Latitude\", \"Work Class\", \"Applied Date\"]\n",
    "featureDrop = [x for x in columnsNames if x not in important_features]\n",
    "print(featureDrop)\n",
    "    \n",
    "fullData = data.drop(featureDrop, axis=1)\n",
    "#data added chronologically to dataset, for now reduce by half for random sampling\n",
    "#pick sample sizes (max is half the dataset due to Darwin restrictions on Big Data)\n",
    "trainSize = math.floor(len(fullData)/2)\n",
    "testSize = math.floor(len(fullData)/10)\n",
    "\n",
    "#sample train and test sets, note currently using .sample() performs without replacement on each instance, meaning\n",
    "#there might exist overlap between the two sets\n",
    "testSet = fullData.sample(n=testSize)\n",
    "trainData = fullData.sample(n=trainSize)\n",
    "\n",
    "#write out datasets to disk to upload later\n",
    "testSet.to_csv(os.path.join(path, test))\n",
    "trainData.to_csv(os.path.join(path, filename))\n",
    "\n",
    "#show data / completed write to disk\n",
    "trainData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook attempts to reduce the overall dataset by using only the features Darwin deems most important. The most important features were calculated from the model in the master notebook then listed here in \"important_features.\" We remove any feature not in that list (with Permit Type as the exception) and sample from the reduced data for the training and testing sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload to Darwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "status, dataset = ds.upload_dataset(os.path.join(path, filename))\n",
    "if not status:\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'job_name': '0172e09334684adc97d60b2c787afd34', 'artifact_name': '36df201c91364e05ac9a812cd9e1a16b'}\n",
      "{'status': 'Requested', 'starttime': '2019-04-22T22:25:39.295079', 'endtime': None, 'percent_complete': 0, 'job_type': 'CleanDataTiny', 'loss': None, 'generations': None, 'dataset_names': ['train.csv'], 'artifact_names': ['36df201c91364e05ac9a812cd9e1a16b'], 'model_name': None, 'job_error': None}\n",
      "{'status': 'Requested', 'starttime': '2019-04-22T22:25:39.295079', 'endtime': None, 'percent_complete': 0, 'job_type': 'CleanDataTiny', 'loss': None, 'generations': None, 'dataset_names': ['train.csv'], 'artifact_names': ['36df201c91364e05ac9a812cd9e1a16b'], 'model_name': None, 'job_error': None}\n",
      "{'status': 'Requested', 'starttime': '2019-04-22T22:25:39.295079', 'endtime': None, 'percent_complete': 0, 'job_type': 'CleanDataTiny', 'loss': None, 'generations': None, 'dataset_names': ['train.csv'], 'artifact_names': ['36df201c91364e05ac9a812cd9e1a16b'], 'model_name': None, 'job_error': None}\n",
      "{'status': 'Running', 'starttime': '2019-04-22T22:25:39.295079', 'endtime': None, 'percent_complete': 0, 'job_type': 'CleanDataTiny', 'loss': None, 'generations': None, 'dataset_names': ['train.csv'], 'artifact_names': ['36df201c91364e05ac9a812cd9e1a16b'], 'model_name': None, 'job_error': ''}\n",
      "{'status': 'Running', 'starttime': '2019-04-22T22:25:39.295079', 'endtime': None, 'percent_complete': 0, 'job_type': 'CleanDataTiny', 'loss': None, 'generations': None, 'dataset_names': ['train.csv'], 'artifact_names': ['36df201c91364e05ac9a812cd9e1a16b'], 'model_name': None, 'job_error': ''}\n",
      "{'status': 'Running', 'starttime': '2019-04-22T22:25:39.295079', 'endtime': None, 'percent_complete': 0, 'job_type': 'CleanDataTiny', 'loss': None, 'generations': None, 'dataset_names': ['train.csv'], 'artifact_names': ['36df201c91364e05ac9a812cd9e1a16b'], 'model_name': None, 'job_error': ''}\n",
      "{'status': 'Running', 'starttime': '2019-04-22T22:25:39.295079', 'endtime': None, 'percent_complete': 0, 'job_type': 'CleanDataTiny', 'loss': None, 'generations': None, 'dataset_names': ['train.csv'], 'artifact_names': ['36df201c91364e05ac9a812cd9e1a16b'], 'model_name': None, 'job_error': ''}\n",
      "{'status': 'Running', 'starttime': '2019-04-22T22:25:39.295079', 'endtime': None, 'percent_complete': 0, 'job_type': 'CleanDataTiny', 'loss': None, 'generations': None, 'dataset_names': ['train.csv'], 'artifact_names': ['36df201c91364e05ac9a812cd9e1a16b'], 'model_name': None, 'job_error': ''}\n",
      "{'status': 'Running', 'starttime': '2019-04-22T22:25:39.295079', 'endtime': None, 'percent_complete': 0, 'job_type': 'CleanDataTiny', 'loss': None, 'generations': None, 'dataset_names': ['train.csv'], 'artifact_names': ['36df201c91364e05ac9a812cd9e1a16b'], 'model_name': None, 'job_error': ''}\n",
      "{'status': 'Running', 'starttime': '2019-04-22T22:25:39.295079', 'endtime': None, 'percent_complete': 0, 'job_type': 'CleanDataTiny', 'loss': None, 'generations': None, 'dataset_names': ['train.csv'], 'artifact_names': ['36df201c91364e05ac9a812cd9e1a16b'], 'model_name': None, 'job_error': ''}\n",
      "{'status': 'Complete', 'starttime': '2019-04-22T22:25:39.295079', 'endtime': '2019-04-22T22:28:05.827868', 'percent_complete': 100, 'job_type': 'CleanDataTiny', 'loss': None, 'generations': None, 'dataset_names': ['train.csv'], 'artifact_names': ['36df201c91364e05ac9a812cd9e1a16b'], 'model_name': None, 'job_error': ''}\n"
     ]
    }
   ],
   "source": [
    "# clean dataset\n",
    "target = \"Permit Type\"\n",
    "index = \"Applied Date\"\n",
    "status, job_id = ds.clean_data(filename, target = target)\n",
    "print(job_id)\n",
    "if status:\n",
    "    ds.wait_for_job(job_id['job_name'])\n",
    "else:\n",
    "    print(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Complete', 'starttime': '2019-04-22T22:25:39.295079', 'endtime': '2019-04-22T22:28:05.827868', 'percent_complete': 100, 'job_type': 'CleanDataTiny', 'loss': None, 'generations': None, 'dataset_names': ['train.csv'], 'artifact_names': ['36df201c91364e05ac9a812cd9e1a16b'], 'model_name': None, 'job_error': ''}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, 'Job completed')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.wait_for_job(job_id['job_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Requested', 'starttime': '2019-04-22T22:32:08.957833', 'endtime': None, 'percent_complete': 0, 'job_type': 'TrainModel', 'loss': None, 'generations': 0, 'dataset_names': ['train.csv'], 'artifact_names': None, 'model_name': 'Permit Type_model', 'job_error': None}\n",
      "{'status': 'Requested', 'starttime': '2019-04-22T22:32:08.957833', 'endtime': None, 'percent_complete': 0, 'job_type': 'TrainModel', 'loss': None, 'generations': 0, 'dataset_names': ['train.csv'], 'artifact_names': None, 'model_name': 'Permit Type_model', 'job_error': None}\n",
      "{'status': 'Requested', 'starttime': '2019-04-22T22:32:08.957833', 'endtime': None, 'percent_complete': 0, 'job_type': 'TrainModel', 'loss': None, 'generations': 0, 'dataset_names': ['train.csv'], 'artifact_names': None, 'model_name': 'Permit Type_model', 'job_error': None}\n",
      "{'status': 'Requested', 'starttime': '2019-04-22T22:32:08.957833', 'endtime': None, 'percent_complete': 0, 'job_type': 'TrainModel', 'loss': None, 'generations': 0, 'dataset_names': ['train.csv'], 'artifact_names': None, 'model_name': 'Permit Type_model', 'job_error': None}\n",
      "{'status': 'Requested', 'starttime': '2019-04-22T22:32:08.957833', 'endtime': None, 'percent_complete': 0, 'job_type': 'TrainModel', 'loss': None, 'generations': 0, 'dataset_names': ['train.csv'], 'artifact_names': None, 'model_name': 'Permit Type_model', 'job_error': None}\n",
      "{'status': 'Requested', 'starttime': '2019-04-22T22:32:08.957833', 'endtime': None, 'percent_complete': 0, 'job_type': 'TrainModel', 'loss': None, 'generations': 0, 'dataset_names': ['train.csv'], 'artifact_names': None, 'model_name': 'Permit Type_model', 'job_error': None}\n",
      "{'status': 'Requested', 'starttime': '2019-04-22T22:32:08.957833', 'endtime': None, 'percent_complete': 0, 'job_type': 'TrainModel', 'loss': None, 'generations': 0, 'dataset_names': ['train.csv'], 'artifact_names': None, 'model_name': 'Permit Type_model', 'job_error': None}\n",
      "{'status': 'Requested', 'starttime': '2019-04-22T22:32:08.957833', 'endtime': None, 'percent_complete': 0, 'job_type': 'TrainModel', 'loss': None, 'generations': 0, 'dataset_names': ['train.csv'], 'artifact_names': None, 'model_name': 'Permit Type_model', 'job_error': None}\n",
      "{'status': 'Requested', 'starttime': '2019-04-22T22:32:08.957833', 'endtime': None, 'percent_complete': 0, 'job_type': 'TrainModel', 'loss': None, 'generations': 0, 'dataset_names': ['train.csv'], 'artifact_names': None, 'model_name': 'Permit Type_model', 'job_error': None}\n",
      "{'status': 'Requested', 'starttime': '2019-04-22T22:32:08.957833', 'endtime': None, 'percent_complete': 0, 'job_type': 'TrainModel', 'loss': None, 'generations': 0, 'dataset_names': ['train.csv'], 'artifact_names': None, 'model_name': 'Permit Type_model', 'job_error': None}\n",
      "{'status': 'Requested', 'starttime': '2019-04-22T22:32:08.957833', 'endtime': None, 'percent_complete': 0, 'job_type': 'TrainModel', 'loss': None, 'generations': 0, 'dataset_names': ['train.csv'], 'artifact_names': None, 'model_name': 'Permit Type_model', 'job_error': None}\n",
      "{'status': 'Requested', 'starttime': '2019-04-22T22:32:08.957833', 'endtime': None, 'percent_complete': 0, 'job_type': 'TrainModel', 'loss': None, 'generations': 0, 'dataset_names': ['train.csv'], 'artifact_names': None, 'model_name': 'Permit Type_model', 'job_error': None}\n",
      "{'status': 'Requested', 'starttime': '2019-04-22T22:32:08.957833', 'endtime': None, 'percent_complete': 0, 'job_type': 'TrainModel', 'loss': None, 'generations': 0, 'dataset_names': ['train.csv'], 'artifact_names': None, 'model_name': 'Permit Type_model', 'job_error': None}\n",
      "{'status': 'Requested', 'starttime': '2019-04-22T22:32:08.957833', 'endtime': None, 'percent_complete': 0, 'job_type': 'TrainModel', 'loss': None, 'generations': 0, 'dataset_names': ['train.csv'], 'artifact_names': None, 'model_name': 'Permit Type_model', 'job_error': None}\n",
      "{'status': 'Requested', 'starttime': '2019-04-22T22:32:08.957833', 'endtime': None, 'percent_complete': 0, 'job_type': 'TrainModel', 'loss': None, 'generations': 0, 'dataset_names': ['train.csv'], 'artifact_names': None, 'model_name': 'Permit Type_model', 'job_error': None}\n",
      "{'status': 'Running', 'starttime': '2019-04-22T22:32:08.957833', 'endtime': None, 'percent_complete': 0, 'job_type': 'TrainModel', 'loss': None, 'generations': 0, 'dataset_names': ['train.csv'], 'artifact_names': None, 'model_name': 'Permit Type_model', 'job_error': ''}\n",
      "{'status': 'Running', 'starttime': '2019-04-22T22:32:08.957833', 'endtime': None, 'percent_complete': 0, 'job_type': 'TrainModel', 'loss': None, 'generations': 0, 'dataset_names': ['train.csv'], 'artifact_names': None, 'model_name': 'Permit Type_model', 'job_error': ''}\n",
      "{'status': 'Running', 'starttime': '2019-04-22T22:32:08.957833', 'endtime': None, 'percent_complete': 0, 'job_type': 'TrainModel', 'loss': None, 'generations': 0, 'dataset_names': ['train.csv'], 'artifact_names': None, 'model_name': 'Permit Type_model', 'job_error': ''}\n",
      "{'status': 'Running', 'starttime': '2019-04-22T22:32:08.957833', 'endtime': None, 'percent_complete': 0, 'job_type': 'TrainModel', 'loss': None, 'generations': 0, 'dataset_names': ['train.csv'], 'artifact_names': None, 'model_name': 'Permit Type_model', 'job_error': ''}\n",
      "{'status': 'Failed', 'starttime': '2019-04-22T22:32:08.957833', 'endtime': '2019-04-22T22:36:50.910057', 'percent_complete': 100, 'job_type': 'TrainModel', 'loss': None, 'generations': 0, 'dataset_names': ['train.csv'], 'artifact_names': None, 'model_name': 'Permit Type_model', 'job_error': 'DarwinInternalError: uncaught'}\n"
     ]
    }
   ],
   "source": [
    "model = target + \"_model\"\n",
    "status, job_id = ds.create_model(dataset_names = filename, \\\n",
    "                                 model_name =  model, \\\n",
    "                                 max_train_time = '00:01', \\\n",
    "                                 max_epochs=0)\n",
    "if status:\n",
    "    ds.wait_for_job(job_id['job_name'])\n",
    "else:\n",
    "    print(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check status of job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Complete', 'starttime': '2019-04-22T22:15:38.563651', 'endtime': '2019-04-22T22:18:31.048386', 'percent_complete': 100, 'job_type': 'CleanDataTiny', 'loss': None, 'generations': None, 'dataset_names': None, 'artifact_names': None, 'model_name': None, 'job_error': ''}\n"
     ]
    }
   ],
   "source": [
    "if status:\n",
    "    ds.wait_for_job(job_id['job_name'])\n",
    "else:\n",
    "    print(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature importance of built model\n",
    "status, artifact = ds.analyze_model(model)\n",
    "sleep(1)\n",
    "if status:\n",
    "    ds.wait_for_job(artifact['job_name'])\n",
    "else:\n",
    "    print(artifact)\n",
    "status, feature_importance = ds.download_artifact(artifact['artifact_name'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display most important features of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions\n",
    "\n",
    "#### Perform model prediction on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status, artifact = ds.run_model(filename, model)\n",
    "sleep(1)\n",
    "ds.wait_for_job(artifact['job_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download predictions from Darwin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "status, prediction = ds.download_artifact(artifact['artifact_name'])\n",
    "prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.to_csv(os.path.join(path, \"prediction10.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create visualizations for comparing predictions with actual target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unq = prediction[target].unique()[::-1]\n",
    "p = np.zeros((len(prediction),))\n",
    "a = np.zeros((len(prediction),))\n",
    "for i,q in enumerate(unq):\n",
    "    p += i*(prediction[target] == q).values\n",
    "    a += i*(reduceData[target] == q).values\n",
    "#Plot predictions vs actual\n",
    "plt.plot(a)\n",
    "plt.plot(p)\n",
    "plt.legend(['Actual','Predicted'])\n",
    "plt.yticks([i for i in range(len(unq))],[q for q in unq]);\n",
    "print(classification_report(reduceData[target], prediction[target]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform model prediction on test dataset from holdout method.\n",
    "Upload test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "status, dataset = ds.upload_dataset(os.path.join(path, test_data))\n",
    "if not status:\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status, job_id = ds.clean_data(test_data, target = target, model_name = model)\n",
    "print(\"Model:\\n\",model)\n",
    "print(\"Target: \\n\",target)\n",
    "print(job_id)\n",
    "if status:\n",
    "    ds.wait_for_job(job_id['job_name'])\n",
    "else:\n",
    "    print(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run model on test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status, artifact = ds.run_model(test_data, model)\n",
    "sleep(1)\n",
    "ds.wait_for_job(artifact['job_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create visualizations for comparing predictions with actual target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status, prediction = ds.download_artifact(artifact['artifact_name'])\n",
    "df = pd.read_csv(os.path.join(path,test_data))\n",
    "unq = prediction[target].unique()[::-1]\n",
    "p = np.zeros((len(prediction),))\n",
    "a = np.zeros((len(prediction),))\n",
    "for i,q in enumerate(unq):\n",
    "    p += i*(prediction[target] == q).values\n",
    "    a += i*(df[target] == q).values\n",
    "#Plot predictions vs actual\n",
    "plt.plot(a)\n",
    "plt.plot(p)\n",
    "plt.legend(['Actual','Predicted'])\n",
    "plt.yticks([i for i in range(len(unq))],[q for q in unq]);\n",
    "print(classification_report(df[target], prediction[target]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Darwin' Pick for machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status, model_type = ds.lookup_model_name(model)\n",
    "print(model_type['description']['best_genome'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting longlat_test.csv\n",
      "Error removing dataset \"longlat_test.csv\" - 403: FORBIDDEN - {\"message\": \"Dataset is in use by an active job\"}\n",
      "\n",
      "Deleting Permit Type_model_loc1\n",
      "Error removing model \"Permit Type_model_loc1\" - 403: FORBIDDEN - {\"message\": \"Model is in use by an active job\"}\n",
      "\n",
      "Deleting 0cad448fa6db4e20845ede356d44edd5\n",
      "Error removing artifact \"0cad448fa6db4e20845ede356d44edd5\" - 404: NOT FOUND - {\"message\": \"Failed to find artifact 0cad448fa6db4e20845ede356d44edd5\"}\n",
      "\n",
      "Deleting f2d6110053354e5b80ece5cdc3668918\n",
      "Error removing artifact \"f2d6110053354e5b80ece5cdc3668918\" - 404: NOT FOUND - {\"message\": \"Failed to find artifact f2d6110053354e5b80ece5cdc3668918\"}\n",
      "\n",
      "Deleting 7a66ffae7ce6480897a4548c8491a2be\n",
      "Error removing artifact \"7a66ffae7ce6480897a4548c8491a2be\" - 404: NOT FOUND - {\"message\": \"Failed to find artifact 7a66ffae7ce6480897a4548c8491a2be\"}\n",
      "\n",
      "Deleting 32cbe86816554c8b9c905cf81e59e145\n",
      "Error removing artifact \"32cbe86816554c8b9c905cf81e59e145\" - 404: NOT FOUND - {\"message\": \"Failed to find artifact 32cbe86816554c8b9c905cf81e59e145\"}\n",
      "\n",
      "Deleting 25f4e215e1b04071ad8c31ade0dac299\n",
      "Error removing artifact \"25f4e215e1b04071ad8c31ade0dac299\" - 404: NOT FOUND - {\"message\": \"Failed to find artifact 25f4e215e1b04071ad8c31ade0dac299\"}\n",
      "\n",
      "Deleting ddf97aa30c7745fdbbfbcf1a745430bd\n",
      "Error removing artifact \"ddf97aa30c7745fdbbfbcf1a745430bd\" - 404: NOT FOUND - {\"message\": \"Failed to find artifact ddf97aa30c7745fdbbfbcf1a745430bd\"}\n",
      "\n",
      "Deleting 4840a49de1c745ceb4961f580b3ae477\n",
      "Error removing artifact \"4840a49de1c745ceb4961f580b3ae477\" - 404: NOT FOUND - {\"message\": \"Failed to find artifact 4840a49de1c745ceb4961f580b3ae477\"}\n",
      "\n",
      "Deleting 2815af07e63f4c8ab9e60e9118077c55\n",
      "Error removing artifact \"2815af07e63f4c8ab9e60e9118077c55\" - 404: NOT FOUND - {\"message\": \"Failed to find artifact 2815af07e63f4c8ab9e60e9118077c55\"}\n",
      "\n",
      "Deleting 8d99645cb4ae4805bb68fe67d90ee584\n",
      "Error removing artifact \"8d99645cb4ae4805bb68fe67d90ee584\" - 404: NOT FOUND - {\"message\": \"Failed to find artifact 8d99645cb4ae4805bb68fe67d90ee584\"}\n",
      "\n",
      "Deleting 1cdce308746e4d25b1d9344524bf1024\n",
      "Error removing artifact \"1cdce308746e4d25b1d9344524bf1024\" - 404: NOT FOUND - {\"message\": \"Failed to find artifact 1cdce308746e4d25b1d9344524bf1024\"}\n",
      "\n",
      "Deleting 6b637bc507a44080b1a52cbff2c85863\n",
      "Error removing artifact \"6b637bc507a44080b1a52cbff2c85863\" - 404: NOT FOUND - {\"message\": \"Failed to find artifact 6b637bc507a44080b1a52cbff2c85863\"}\n",
      "\n",
      "Deleting 953f1e473c6641bc8932f5afc87fcd99\n",
      "Error removing artifact \"953f1e473c6641bc8932f5afc87fcd99\" - 404: NOT FOUND - {\"message\": \"Failed to find artifact 953f1e473c6641bc8932f5afc87fcd99\"}\n",
      "\n",
      "Deleting 4de605b0816e410ab1ff68f36c33c5d2\n",
      "Error removing artifact \"4de605b0816e410ab1ff68f36c33c5d2\" - 404: NOT FOUND - {\"message\": \"Failed to find artifact 4de605b0816e410ab1ff68f36c33c5d2\"}\n",
      "\n",
      "Deleting 7d8c21ef87ea492cbd616ab6242a0bff\n",
      "Error removing artifact \"7d8c21ef87ea492cbd616ab6242a0bff\" - 404: NOT FOUND - {\"message\": \"Failed to find artifact 7d8c21ef87ea492cbd616ab6242a0bff\"}\n",
      "\n",
      "Deleting 60a21fd8551e434fbf305bd75c1a8724\n",
      "Error removing artifact \"60a21fd8551e434fbf305bd75c1a8724\" - 404: NOT FOUND - {\"message\": \"Failed to find artifact 60a21fd8551e434fbf305bd75c1a8724\"}\n",
      "\n",
      "Deleting 865beb8cc7114b49aad7cbf51f64ae83\n",
      "Error removing artifact \"865beb8cc7114b49aad7cbf51f64ae83\" - 404: NOT FOUND - {\"message\": \"Failed to find artifact 865beb8cc7114b49aad7cbf51f64ae83\"}\n",
      "\n",
      "Deleting b455258e25cd4de49f5c3b05b3ab38f7\n",
      "Error removing artifact \"b455258e25cd4de49f5c3b05b3ab38f7\" - 404: NOT FOUND - {\"message\": \"Failed to find artifact b455258e25cd4de49f5c3b05b3ab38f7\"}\n",
      "\n",
      "Deleting 809c487ecd074e5ba7d908dece2ec101\n",
      "Error removing artifact \"809c487ecd074e5ba7d908dece2ec101\" - 404: NOT FOUND - {\"message\": \"Failed to find artifact 809c487ecd074e5ba7d908dece2ec101\"}\n",
      "\n",
      "Deleting 5aa409b2cb104a94836995cb72b299b1\n",
      "Error removing artifact \"5aa409b2cb104a94836995cb72b299b1\" - 404: NOT FOUND - {\"message\": \"Failed to find artifact 5aa409b2cb104a94836995cb72b299b1\"}\n",
      "\n",
      "Deleting a2f512791dc441f8913016db25848ece\n",
      "Error removing artifact \"a2f512791dc441f8913016db25848ece\" - 404: NOT FOUND - {\"message\": \"Failed to find artifact a2f512791dc441f8913016db25848ece\"}\n",
      "\n",
      "Deleting 2d9732b07f9d460985bf01e8310d4c2f\n",
      "Error removing artifact \"2d9732b07f9d460985bf01e8310d4c2f\" - 404: NOT FOUND - {\"message\": \"Failed to find artifact 2d9732b07f9d460985bf01e8310d4c2f\"}\n",
      "\n",
      "Deleting 32e4d7a8c0e446e097c6e55beb2a3fec\n",
      "Error removing artifact \"32e4d7a8c0e446e097c6e55beb2a3fec\" - 404: NOT FOUND - {\"message\": \"Failed to find artifact 32e4d7a8c0e446e097c6e55beb2a3fec\"}\n",
      "\n",
      "Deleting c81882dd77a24ce7b69853f9f43cf700\n",
      "Error removing artifact \"c81882dd77a24ce7b69853f9f43cf700\" - 404: NOT FOUND - {\"message\": \"Failed to find artifact c81882dd77a24ce7b69853f9f43cf700\"}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.delete_all_datasets()\n",
    "ds.delete_all_models()\n",
    "ds.delete_all_artifacts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
